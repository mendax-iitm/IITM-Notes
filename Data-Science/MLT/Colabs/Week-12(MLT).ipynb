{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week-12(MLT).ipynb","provenance":[],"authorship_tag":"ABX9TyNdGEJoxarI73OXNvZiAhjs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Artificial Neural Network"],"metadata":{"id":"VS1dMn1fFqJB"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"WtIAcgzoFVcl","executionInfo":{"status":"ok","timestamp":1658415740650,"user_tz":-330,"elapsed":2,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"outputs":[],"source":["import numpy as np\n","seed=42\n","rng=np.random.default_rng(seed=seed)"]},{"cell_type":"markdown","source":["## Network Class"],"metadata":{"id":"nwJMFTGYGBY0"}},{"cell_type":"markdown","source":["We shall start writing the `Network` class. The two methods that are indispensable for any ML class are:  \n","- fit\n","- predict\n","\n","Fitting a neural network model required us to compute two passes on the data:\n","- forward\n","- backward\n","\n","We need to start at some place by initializing the network and various hyper-parameters and this requires an `init` method:\n","- init\n","\n","In most of these methods, we would have to take help of certain helper functions:\n","- activations\n","- losses\n","This is the process. But we will work through it in the reverse order so that each step of the process does not have any forward references:\n","\n","`helpers -> init -> forward -> backward -> fit -> predict`\n","\n","The skeleton of the class is given in the code block that follows. For ease of exposition, we are going to discuss the methods one at a time and then plug them into the class right at the end."],"metadata":{"id":"SxphhhBBGt_y"}},{"cell_type":"code","source":["class Network:\n","\n","  def init(self, layers, activation_choice='relu', output_choice='softmax', loss_choice='cce'):\n","    pass\n","\n","  def forward(self,X):\n","    pass\n","  def backward(self,Y,Y_hat):\n","    pass\n","\n","  def fit(self,X,Y,lr=0.01, epochs=100,\n","          batch_size=100):\n","    pass\n","  def predict(self,X):\n","    pass"],"metadata":{"id":"b6j9Bsp9F_zO","executionInfo":{"status":"ok","timestamp":1658415740651,"user_tz":-330,"elapsed":2,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Activation functions\n","\n","### Hidden Layer\n","We will look at two activation functions for the hidden layers. Both these functions will be applied element wise. The input to these functions can be scalars, vectors or matrices/\n","Sigmoid\n","$$g(z)=\\frac{1}{1+e^{-z}}$$\n","ReLU\n","$$g(z)=\\begin{cases}z, &z\\geq0\\\\\n","0 & z<0\n","\\end{cases}$$\n","\n","We also need to find out the derivatives of these functions while computing the backward pass. Deriving the mathematical expressions for them are left as an exercise to the learners"],"metadata":{"id":"wSWNZL8jRQfP"}},{"cell_type":"code","source":["def sigmoid(z):\n","  return 1/(1+np.exp(-z))\n","\n","def grad_sigmoid(z):\n","  return sigmoid(z)*(1-sigmoid(z))\n","\n","def relu(z):\n","  return np.where(z>=0,z,0)\n","\n","def grad_relu(z):\n","  return np.where(z>=0,1,0)\n","\n","# A dictionary of activation functions\n","# will be used while intializing the network\n","hidden_act = {'sigmoid':sigmoid, 'relu':relu}\n","grad_hidden_act={'sigmoid':grad_sigmoid,'relu':grad_relu}"],"metadata":{"id":"grANzRVIRItp","executionInfo":{"status":"ok","timestamp":1658415840712,"user_tz":-330,"elapsed":7,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Output Layer\n","We will look at two activation functions for the output layer. Identity for regression and Softmax for classification.\n","\n","###Identity\n","$$g(z)=z$$\n","\n","###Softmax\n","The input to the softmax function will always be a matrix of size $n\\times k$ where k is the number of classes. Since we need a probability distribution for each data-point, the softmax will be computed row-wise\n"," $$g(z)=\\Large{[...\\frac{e^{z_i}}{\\sum e^{z_j}}....]}$$ \n"," to avoid the overflow, we will subtract the row-wise maximum from each row while computing the softmax.\n"],"metadata":{"id":"PUyzd1MZSXgk"}},{"cell_type":"code","source":["def identity(z):\n","  return z\n","\n","def softmax(z):\n","  \"\"\"\n","  Row-wise softmax\n","  \"\"\"\n","  #check if z is a matrix\n","  assert z.ndim==2\n","  # To prevent overflow, subtract max, row wise\n","  z-=z.max(axis=1, keepdims=True)\n","  #Compute rowwise softmax\n","  prob=np.exp(z)/np.exp(z).sum(axis=1, keepdims= True)\n","  #Check if row is probability distribution\n","  assert np.allclose(prob.sum(axis=1),np.ones(z.shape[0]))\n","  return prob\n","\n","output_act={'softmax':softmax, 'identity':identity}\n","  "],"metadata":{"id":"C1KCfy-FT7Xr","executionInfo":{"status":"ok","timestamp":1658416601444,"user_tz":-330,"elapsed":6,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["##Loss\n","There are two types of losses we will use, least square error for regression and categorical cross-entropy for classification\n","\n","### Least Square\n","- y is a vector of target labels for n data-points\n","- $\\hat{y}$ is the output of the network and corresponds to the predicted labels.\n","\n","$$L(y,\\hat{y})=\\frac{1}{2}.(\\hat{y}-y)^T(\\hat{y}-y)$$\n","### Categorical Cross-Entropy\n","- Y is a matrix of target labels for n data-points\n","- $\\hat{Y}$ is the output of the network and corresponds to the predicted probabilities\n","$$L(Y,\\hat{Y})=-1_n^T(Y\\bigodot log\\hat{Y})1_k$$\n","In our implementation,we will assume that the arguments to the loss function are always matrices of size $n \\times k$. In case of regression, k=1.\n"],"metadata":{"id":"Iny80godVRO1"}},{"cell_type":"code","source":["def least_square(y,y_hat):\n","  return 0.5*np.sum((y_hat-y)*(y_hat-y))\n","\n","def cce(Y, Y_hat):\n","  return -np.sum(Y*np.log(Y_hat))\n","\n","losses={'least_square':least_square,'cce':cce}"],"metadata":{"id":"C8uwyxffaZkB","executionInfo":{"status":"ok","timestamp":1658418062681,"user_tz":-330,"elapsed":6,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Initialization\n","Here will look at two parts:\n","- Network architecture\n","- Weight initialization\n","\n","## Network architecture\n","The follwing components mainly determine the structure of the network:\n","- number of layers\n","- number of neurons per layer\n","\n","We will use $l$ to index the layers. The network has L layers in all.\n","- $l=0$: input layer\n","- $1\\leq l \\leq L-1:$ Hidden layers\n","- $l=L$: Output Layer\n","\n","We shall represent the number of layers and the neurons using a list `layers`. The variable L will never make an explicit appearance anywhere, instead we will use `range(len(layers))` to iterate through the layers.\n","\n","\n","One useful task is to compute the total number of parameters in the network. This will come in handy later on"],"metadata":{"id":"38Vy9XL1a18f"}},{"cell_type":"code","source":["def count_params(layers):\n","  num_params=0\n","  for l in range(1,len(layers)):\n","    num_weights= layers[l-1]*layers[l]\n","    num_biases=layers[l]\n","    num_params+=(num_weights +num_biases)\n","  return num_params\n","\n","assert count_params([64,5,10]) == (64*5+5)+(5*10+10)"],"metadata":{"id":"RMln13mOnTJv","executionInfo":{"status":"ok","timestamp":1658421768743,"user_tz":-330,"elapsed":435,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Parameter initialisation\n","\n","The weight-matrix at layer $l$ has size `layer[l-1]*layers[l]`.The bias at layer $l$ is a vector of size `layers[l]`. We will stoire all these weights in a list W of the same size as layers. `W[l]` would correspond to $W_1$. Since there are L weight matrices, `W[0]` would be set to `None.` Recall that the size of the list is L+1. A similar list would be required for b.\n","\n","To make the gradient descent update simpler, it will be useful to a have a **master vector,$\\theta$** that has a reference to all the parameters in the network. We will do the same for the gradients $\\theta^{(g)}$. So whenver $\\theta$ is updated, the weights $W_1$ will also be updated and vice-versa.\n","\n","One way to do this is to first start with the master vector and then reshape chunks of it into the dimensions of a weight matrix. Reshaping an array usually returns a view of an array and not a copy. To understand this function better, refer to Numpy's documentation on \"Copies and Views\""],"metadata":{"id":"Tqsc0l2kn_De"}},{"cell_type":"code","source":["def init_params(layers):\n","  num_params = count_params(layers)\n","\n","  W= [None for _ in range(len(layers))]   #weights\n","  b= [None for _ in range(len(layers))]   # biases\n","  gW= [None for _ in range(len(layers))]  # grad loss w.r.t weights\n","  gb= [None for _ in range(len(layers))]  # grad ;pss w.r.t biases\n","\n","  # Sample from N(0,1) to initialize the params\\\n","  theta = rng.standard_normal(num_params)   #master params\n","  gtheta = np.zeros(num_params)             # master grads\n","\n","  # (start, end) specify the portion of the theta\n","  # that corresponds to the parameter, W_1 or b_1\n","  start, end =0, 0\n","  for l in range(1, len(layers)):\n","    #Reshape the section (Start, end) and assign it to W[1]\n","    end= start+layers[l-1]*layers[l]\n","    W[l]=theta[start:end].reshape(layers[l-1],layers[l])\n","    gW[l]=gtheta[start:end].reshape(layers[l-1],layers[l])\n","\n","    #Reshape the section (start, end) and assign it to b[1]\n","    start, end = end, end+layers[l]\n","    b[l]=theta[start:end].reshape(layers[l])\n","    gb[l]=gtheta[start:end].reshape(layers[l])\n","    start=end\n","\n","  return theta, gtheta, W, b, gW, gb\n","\n","## Test init params\n","layers = [64,32,10]\n","params = init_params([64,32,10])\n","for l in range(1, len(layers)):\n","  # Check if the weights are views of the master vector\n","  assert params[2][l].base is params[0]\n","  assert params[3][l].base is params[0]\n","  assert params[4][l].base is params[1]\n","  assert params[5][l].base is params[1]\n","  "],"metadata":{"id":"ugG9XiYdr33c","executionInfo":{"status":"ok","timestamp":1658424564525,"user_tz":-330,"elapsed":406,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["print(params[2][1])\n","print('________________')\n","print(params[2][1].base)\n","print('________________')\n","print(params[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6_n3vJ3zWlr","executionInfo":{"status":"ok","timestamp":1658424696583,"user_tz":-330,"elapsed":457,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}},"outputId":"b6927213-0077-4146-877c-ac0219484b5e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.47100026 -0.67231587  1.46972376 ...  0.02454983 -0.32134253\n","  -0.20118976]\n"," [ 2.0371279  -1.76200024 -0.23467682 ...  0.27200111 -0.62831999\n","  -0.27836644]\n"," [ 0.44135869 -0.34877268  0.22605959 ... -1.08830779  1.19681671\n","   0.10231033]\n"," ...\n"," [ 0.02975074 -0.26400449 -1.16775192 ...  1.05053365 -0.1231803\n","   0.61157937]\n"," [ 0.67101243 -0.45244034  1.09190644 ... -1.13826398  0.39963069\n","   0.01438969]\n"," [ 0.34750931 -0.51977195  1.38313514 ...  0.48117409 -0.58571153\n","   0.14687517]]\n","________________\n","[-0.47100026 -0.67231587  1.46972376 ...  0.53943852 -0.93714921\n","  0.91823253]\n","________________\n","[-0.47100026 -0.67231587  1.46972376 ...  0.53943852 -0.93714921\n","  0.91823253]\n"]}]},{"cell_type":"code","source":["def init(self, layers, activation_choice='relu',\n","         output_choice='softmax',\n","         loss_choice='cce'):\n","  self.layers=layers\n","\n","  #Parameters and gradients\n","  self.theta, self.gtheta, self.W, self.b, self.gW, self.gb=init_params(layers)\n","\n","  #Activation functions\n","  self.ghid=hidden_act[activation_choice]\n","  self.grad_ghid = grad_hidden_act[activation_choice]\n","  self.gout = output_act[output_choice]\n","\n","  #Loss\n","  self.loss=losses[loss_choice]"],"metadata":{"id":"UqYjp_Q5zvMD","executionInfo":{"status":"ok","timestamp":1658425353596,"user_tz":-330,"elapsed":399,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## Forward Pass\n","The foward pass algorithm is as follows. First, we initialize **$A_0=X$**. Then, we iteratively compute the pre-activations and the activations for every layer l uysing the equations given below:\n","$$Z_l=A_{l-1}W_l+b_l$$\n","$$A_l=g(Z_l)$$\n"," finally the output is given by $\\hat{y}=A_L$\n"," "],"metadata":{"id":"19-nkUks2qEo"}},{"cell_type":"code","source":["def forward(self,X):\n","  self.Z=[None for _ in range(len(self.layers))]\n","  self.A=[None for _ in range(len(self.layers))]\n","  self.A[0]=X\n","  self.Z[0]=X\n","\n","  for l in range(1, len(self.layers)):\n","    self.Z[l]=self.A[l-1]@self.W[l]+self.b[l]\n","    self.A[l]=self.ghid(self.Z[l])\n","\n","  self.A[-1]=self.gout(self.Z[-1])\n","  return self.A[-1]"],"metadata":{"id":"FPtXJnZD3z6k","executionInfo":{"status":"ok","timestamp":1658425975288,"user_tz":-330,"elapsed":418,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## Backward PAss\n","The backward pass algorithm is as follows. We first initalize the gradienbts of the pre-activations at layer L as $Z_L^{(g)}=\\hat{Y}-Y$. It is fortunate that this is true for both regression and classification!. The other gradients can then be iteratively updated using these equations:\n","![image info](https://bit.ly/3cvus3Y)\n","\n","An important point ot note is the use of `self.gW[1][:,:]` while updating the gradient of the weights and not `self.gW[l].``self.gW[l][:,:]` does an in-place update, thus maintaining a link with the master params, namely `self.theta`"],"metadata":{"id":"HbsirAm65B2c"}},{"cell_type":"code","source":["def backward(self,Y,Y_hat):\n","  gZ=[None for _ in range(len(self.layers))]\n","  gA=[None for _ in range(len(self.layers))]\n","  gZ[-1]=Y_hat - Y\n","\n","  for l in range(len(self.layers)-1,0,-1):\n","    self.gW[l][:,:]=self.A[l-1].T@gZ[l]\n","    self.gb[l][:]=np.sum(gZ[l].T, axis=1)\n","    gA[l-1]=gZ[l]@self.W[l].T\n","    gZ[l-1]=gA[l-1]*self.grad_ghid(self.Z[l-1])"],"metadata":{"id":"Q_fYnUpR8Xig","executionInfo":{"status":"ok","timestamp":1658429428088,"user_tz":-330,"elapsed":4,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["##Fit"],"metadata":{"id":"oEb6HxHHAMbw"}},{"cell_type":"code","source":["def fit(self,X,Y,lr=0.01,\n","        epochs=100,\n","        batch_size=100):\n","  self.losses=[]\n","\n","  for epoch in range(epochs):\n","    #Compute the loss\n","    Y_hat=self.forward(X)\n","    self.losses.append(self.loss(Y,Y_hat))\n","    #Shuffle the dataset\n","    indices=np.arange(X.shape[0])\n","    #Use rng.shuffle to maintain reproducibility\n","    rng.shuffle(indices)\n","    X,Y=X[indices], Y[indices]\n","    #Number of batches\n","    num_batches = X.shape[0]//batch_size\n","    #Mini-batch GD\n","    for b in range(num_batches):\n","      Xb=X[b*batch_size:(b+1)*batch_size]\n","      Yb=Y[b*batch_size:(b+1)*batch_size]\n","      #Compute the predictions for this batch\n","      Y_hat_b=self.forward(Xb)\n","      #Compute the gradients for this batch\n","      self.backward(Yb,Y_hat_b)\n","      #Update the gradients of all parameters\n","      # -= is used for inplace update\n","      self.theta -= lr*self.gtheta"],"metadata":{"id":"BEAFvaSoAPqr","executionInfo":{"status":"ok","timestamp":1658428281899,"user_tz":-330,"elapsed":402,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Predict"],"metadata":{"id":"5njUUaQzAnzC"}},{"cell_type":"code","source":["def predict(self,X):\n","  Y_hat=self.forward(X)\n","  #regression\n","  if X.shape[-1]==1:\n","    return Y_hat\n","  #classification\n","  else:\n","    return np.argmax(Y_hat,axis=1)"],"metadata":{"id":"uihfN66GB5Ul","executionInfo":{"status":"ok","timestamp":1658428412336,"user_tz":-330,"elapsed":424,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Plugging in"],"metadata":{"id":"R0GY2mESCU0-"}},{"cell_type":"code","source":["Network.__init__=init\n","Network.forward=forward\n","Network.backward=backward\n","Network.fit=fit\n","Network.predict=predict"],"metadata":{"id":"A-YzoPazCZch","executionInfo":{"status":"ok","timestamp":1658429457164,"user_tz":-330,"elapsed":578,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["##DAta"],"metadata":{"id":"xh3UiiTFCmtn"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.datasets import load_digits\n","digits=load_digits()\n","\n","X=digits.images\n","#Normalize the data so that all features lie in (0,1)\n","X /=np.max(X)\n","y=digits.target\n","plt.imshow(X[0])\n","print(f'Sample image with label {y[0]}')\n","print(X.shape)\n","\n","#Reshpe input\n","X= X.reshape(-1,64)\n","#Input size\n","isize=X.shape[-1]\n","\n","#Output size\n","osize=len(np.unique(y))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"z8SXGTtTCpWo","executionInfo":{"status":"ok","timestamp":1658428783388,"user_tz":-330,"elapsed":1176,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}},"outputId":"e032741a-0c0c-48fe-a25e-5b84400c2f7d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample image with label 0\n","(1797, 8, 8)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALGUlEQVR4nO3d/6uW9R3H8ddrR81Vplu2Co8sGSXEYlnOIUYwpWErKthYCjUWA2FQFMmiRmPbPxDuhxGI1YJc0qwgWl8Wq2iBM7/kKr8Nk4ZHKo2+C6kn3/vh3ILFsXPd97muz3Wf954PkM6Xm/vzvrGn132uc9/XxxEhAHl8re0BANSLqIFkiBpIhqiBZIgaSGZSE3c6xafEVJ3WxF23anhm2cd0zjnvF1tr/6EZxdaaOnS02FpxdLjYWiV9pkM6Eoc92vcaiXqqTtMPvKSJu27Vez9ZWHS9X69cV2yt3265tthaF9z+drG1ht95t9haJW2Mf5z0ezz9BpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSqRS17aW2d9veY/vOpocC0Lsxo7Y9IOlPkq6UdKGk5bYvbHowAL2pcqReIGlPROyNiCOS1kkq90JhAF2pEvUsSftO+Hyo87UvsL3C9mbbm4/qcF3zAehSbSfKImJ1RMyPiPmTdUpddwugS1Wi3i9p9gmfD3a+BqAPVYl6k6Tzbc+xPUXSMklPNDsWgF6NeZGEiBi2fbOkZyUNSLo/IrY3PhmAnlS68klEPCXpqYZnAVADXlEGJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJNPIDh1ZldwxQ5KWTfug2FqrZnxabK2/bX222FqX/v5XxdaSpJmrNxRdbzQcqYFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSKbKDh332z5g+40SAwEYnypH6j9LWtrwHABqMmbUEfGSpPcLzAKgBrW9S8v2CkkrJGmqTq3rbgF0iW13gGQ4+w0kQ9RAMlV+pfWwpA2S5toesv3L5scC0Ksqe2ktLzEIgHrw9BtIhqiBZIgaSIaogWSIGkiGqIFkiBpIZsJvuzO8+NJiay2btq3YWpJ05dJlxdaa/tquYmv97OUlxdZ6f97nxdaSpJlFVxsdR2ogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpKpco2y2bZfsL3D9nbbt5YYDEBvqrz2e1jSyojYanuapC22n4uIHQ3PBqAHVbbdeTsitnY+/kTSTkmzmh4MQG+6epeW7fMkzZO0cZTvse0O0AcqnyizfbqkRyXdFhEff/n7bLsD9IdKUduerJGg10bEY82OBGA8qpz9tqT7JO2MiHuaHwnAeFQ5Ui+SdKOkxba3df78uOG5APSoyrY7L0tygVkA1IBXlAHJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQzITfS+uzM8s9hLsPXFRsLUk6VnB/q5I2vf6dtkdIjSM1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZBMlQsPTrX9iu1/d7bd+UOJwQD0psprLA9LWhwRn3YuFfyy7acj4l8NzwagB1UuPBiSPu18OrnzJ5ocCkDvql7Mf8D2NkkHJD0XEaNuu2N7s+3NR3W47jkBVFQp6oj4PCIuljQoaYHt745yG7bdAfpAV2e/I+JDSS9IWtrMOADGq8rZ77Nsz+h8/HVJV0jK+UZfIIEqZ7/PlfSg7QGN/CPwSEQ82exYAHpV5ez3axrZkxrABMAryoBkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIZuJvu/ONcv8urd2wsNhaknSBXim6XimTph8pttbwR1OKrdUvOFIDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZBM5ag7F/R/1TYXHQT6WDdH6lsl7WxqEAD1qLrtzqCkqyStaXYcAONV9Ui9StIdko6d7AbspQX0hyo7dFwt6UBEbPmq27GXFtAfqhypF0m6xvZbktZJWmz7oUanAtCzMaOOiLsiYjAizpO0TNLzEXFD45MB6Am/pwaS6epyRhHxoqQXG5kEQC04UgPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJTPhtd6Z+cNL3mNTu+xe9WWwtSfqo4FqTzjm72FrXX/iVbyOo1SNPX1ZsrX7BkRpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWQqvUy0cyXRTyR9Lmk4IuY3ORSA3nXz2u8fRsR7jU0CoBY8/QaSqRp1SPq77S22V4x2A7bdAfpD1affl0XEftvfkvSc7V0R8dKJN4iI1ZJWS9IZ/mbUPCeAiiodqSNif+e/ByQ9LmlBk0MB6F2VDfJOsz3t+MeSfiTpjaYHA9CbKk+/z5b0uO3jt/9LRDzT6FQAejZm1BGxV9L3CswCoAb8SgtIhqiBZIgaSIaogWSIGkiGqIFkiBpIZsJvu3PG7nKb0/xu8Mlia0nSz1fcXmytydcdLLZWSXPu2tD2CMVxpAaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIJlKUdueYXu97V22d9pe2PRgAHpT9bXff5T0TET81PYUSac2OBOAcRgzatvTJV0u6ReSFBFHJB1pdiwAvary9HuOpIOSHrD9qu01net/fwHb7gD9oUrUkyRdIuneiJgn6ZCkO798o4hYHRHzI2L+ZJ1S85gAqqoS9ZCkoYjY2Pl8vUYiB9CHxow6It6RtM/23M6Xlkja0ehUAHpW9ez3LZLWds5875V0U3MjARiPSlFHxDZJ8xueBUANeEUZkAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8lM+L20jr22q9ha19+7sthaknT3yoeLrbXqzSXF1tp08UCxtf4fcaQGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIZM2rbc21vO+HPx7ZvKzEcgO6N+TLRiNgt6WJJsj0gab+kxxueC0CPun36vUTSmxHx3yaGATB+3b6hY5mkUd9lYHuFpBWSNJX984DWVD5Sd675fY2kv472fbbdAfpDN0+/r5S0NSLebWoYAOPXTdTLdZKn3gD6R6WoO1vXXiHpsWbHATBeVbfdOSTpzIZnAVADXlEGJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDKOiPrv1D4oqdu3Z86U9F7tw/SHrI+Nx9Web0fEWaN9o5Goe2F7c0TMb3uOJmR9bDyu/sTTbyAZogaS6aeoV7c9QIOyPjYeVx/qm5+pAdSjn47UAGpA1EAyfRG17aW2d9veY/vOtuepg+3Ztl+wvcP2dtu3tj1TnWwP2H7V9pNtz1In2zNsr7e9y/ZO2wvbnqlbrf9M3dkg4D8auVzSkKRNkpZHxI5WBxsn2+dKOjcittqeJmmLpOsm+uM6zvbtkuZLOiMirm57nrrYflDSPyNiTecKuqdGxIdtz9WNfjhSL5C0JyL2RsQRSeskXdvyTOMWEW9HxNbOx59I2ilpVrtT1cP2oKSrJK1pe5Y62Z4u6XJJ90lSRByZaEFL/RH1LEn7Tvh8SEn+5z/O9nmS5kna2O4ktVkl6Q5Jx9oepGZzJB2U9EDnR4s1nYtuTij9EHVqtk+X9Kik2yLi47bnGS/bV0s6EBFb2p6lAZMkXSLp3oiYJ+mQpAl3jqcfot4vafYJnw92vjbh2Z6skaDXRkSWyysvknSN7bc08qPSYtsPtTtSbYYkDUXE8WdU6zUS+YTSD1FvknS+7TmdExPLJD3R8kzjZtsa+dlsZ0Tc0/Y8dYmIuyJiMCLO08jf1fMRcUPLY9UiIt6RtM/23M6XlkiacCc2u90gr3YRMWz7ZknPShqQdH9EbG95rDosknSjpNdtb+t87TcR8VSLM2Fst0ha2znA7JV0U8vzdK31X2kBqFc/PP0GUCOiBpIhaiAZogaSIWogGaIGkiFqIJn/ASA9oV0xPR7gAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["def one_hot_encoder(y):\n","  k=len(np.unique(y))\n","  return np.eye(k)[y]\n","  "],"metadata":{"id":"eaucMYXmDvMv","executionInfo":{"status":"ok","timestamp":1658428832849,"user_tz":-330,"elapsed":412,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y,\n","                                                    test_size=0.4,\n","                                                    random_state=seed)\n","Y_train=one_hot_encoder(y_train)\n","Y_test = one_hot_encoder(y_test)\n"],"metadata":{"id":"wJF3xQTLD7gL","executionInfo":{"status":"ok","timestamp":1658428952780,"user_tz":-330,"elapsed":508,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["##Fit!?"],"metadata":{"id":"CVveO4MLEWPn"}},{"cell_type":"code","source":["layers=[isize, 32,osize]\n","network =Network(layers, activation_choice='sigmoid',\n","                          output_choice='softmax',\n","                          loss_choice='cce')\n","#Fit the network on the data\n","epochs=50\n","network.fit(X_train, Y_train, lr=0.01, epochs=epochs, batch_size=10)\n","\n","#Plot the losses\n","plt.figure(figsize=(8,8))\n","plt.plot(range(epochs),network.losses)\n","plt.title('Loss vs Epochs')\n","plt.xlabel('Epcohs')\n","plt.ylabel('CCE Loss')\n","\n","#Compute the accuracy\n","accuracy= np.sum(network.predict(X_test)==y_test)/X_test.shape[0]*100\n","print(f'TEst-data size={X_test.shape[0]}')\n","print(f'Accuracy={accuracy:.2f}')\n","print(f'Number of parameters={count_params(layers)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":565},"id":"mbcHnBisEedg","executionInfo":{"status":"ok","timestamp":1658429470791,"user_tz":-330,"elapsed":4025,"user":{"displayName":"ABHISHEK KUMAR","userId":"12226044567904112342"}},"outputId":"e6f185d3-7a28-470e-9a62-ff66ff582633"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["TEst-data size=719\n","Accuracy=96.52\n","Number of parameters=2410\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 576x576 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[""],"metadata":{"id":"--frUSO-Fxls"},"execution_count":null,"outputs":[]}]}